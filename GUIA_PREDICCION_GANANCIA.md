# Gu√≠a: Predicci√≥n de Ganancia con Machine Learning

## üìã Descripci√≥n General

Esta gu√≠a explica c√≥mo usar el sistema para predecir la **ganancia** de pel√≠culas bas√°ndose en caracter√≠sticas como nombre, pa√≠s, g√©nero, inversi√≥n y fecha. Este es un problema de **regresi√≥n**, donde el objetivo es predecir un valor num√©rico continuo.

## üéØ Concepto: ¬øQu√© es Regresi√≥n?

**Regresi√≥n** es una tarea de Machine Learning donde predecimos un **valor num√©rico** bas√°ndonos en otras caracter√≠sticas.

### Ejemplo con Pel√≠culas

**Datos de entrada:**
```
| nombre          | pais   | genero | inversion | fecha      | ganancia |
|-----------------|--------|--------|-----------|------------|----------|
| Avatar          | USA    | Sci-Fi | 237000000 | 2009-12-18 | 2847246203 |
| Titanic         | USA    | Drama  | 200000000 | 1997-12-19 | 2187463944 |
| Avengers        | USA    | Action | 220000000 | 2012-05-04 | 1518812988 |
| Parasite        | Korea  | Drama  | 11400000  | 2019-05-30 | 258800000  |
```

**Objetivo:** Predecir la columna `ganancia` usando las dem√°s columnas como caracter√≠sticas.

**Pregunta que responde el modelo:**
> "Dada la inversi√≥n, pa√≠s, g√©nero y fecha de una pel√≠cula, ¬øcu√°nto ganar√°?"

## üöÄ Paso a Paso: Entrenar Modelo de Predicci√≥n

### Paso 1: Preparar los Datos

1. **Cargar datos** en el m√≥dulo "Cargar Datos"
   - Sube un archivo CSV con columnas: `nombre`, `pais`, `genero`, `inversion`, `fecha`, `ganancia`
   - O conecta a una base de datos con esta informaci√≥n

2. **Limpiar datos** (opcional) en el m√≥dulo "Limpiar Datos"
   - Elimina valores nulos
   - Normaliza texto (may√∫sculas/min√∫sculas)
   - Elimina duplicados

### Paso 2: Configurar el Modelo

1. Abre el m√≥dulo **"Entrenar Modelos"**

2. Selecciona el **framework**:
   - **Scikit-learn**: M√°s r√°pido, ideal para datasets peque√±os/medianos
   - **PyTorch**: M√°s potente, ideal para datasets grandes

3. **Configuraci√≥n para Scikit-learn:**
   ```
   Caracter√≠sticas (X): Selecciona columnas como: pais, genero, inversion, fecha
   Objetivo (Y): ganancia
   Tipo de Tarea: Regresi√≥n ‚≠ê
   Tipo de modelo: Random Forest (recomendado) o Gradient Boosting
   Tama√±o del conjunto de prueba: 20%
   ```

4. **Configuraci√≥n para PyTorch:**
   ```
   Caracter√≠sticas (X): Selecciona columnas como: pais, genero, inversion, fecha
   Objetivo (Y): ganancia
   Tipo de Tarea: Regresi√≥n ‚≠ê
   Capas ocultas: 3
   Neuronas por capa: 128
   √âpocas: 50
   Tama√±o del conjunto de prueba: 20%
   ```

### Paso 3: Entrenar el Modelo

1. Click en **"Entrenar Modelo"**
2. Espera a que complete (ver√°s una barra de progreso)
3. El sistema autom√°ticamente:
   - Divide los datos en 80% entrenamiento, 20% prueba
   - Preprocesa las caracter√≠sticas (escala n√∫meros, codifica categor√≠as)
   - Entrena el modelo
   - Eval√∫a el rendimiento

### Paso 4: Ver Resultados y Predicciones

1. Click en **"Siguiente: Ver Resultados"** o abre el m√≥dulo "Resultados"

2. En la pesta√±a **"M√©tricas"** ver√°s:
   - **R¬≤ Score**: Qu√© tan bien el modelo explica la varianza (0-1, m√°s alto = mejor)
   - **RMSE**: Error cuadr√°tico medio (m√°s bajo = mejor)
   - **MAE**: Error absoluto medio (m√°s bajo = mejor)

3. En la pesta√±a **"Predicciones"** ver√°s:
   - Lista de predicciones con valores reales vs predichos
   - **Gr√°fico de l√≠neas**: Comparaci√≥n visual real vs predicho
   - **Gr√°fico de errores**: Distribuci√≥n del error por predicci√≥n
   - **Gr√°fico de dispersi√≥n**: Correlaci√≥n entre valores reales y predichos
   - **Estad√≠sticas de error**: Error promedio, m√≠nimo y m√°ximo

## üìä Interpretaci√≥n de Resultados

### Ejemplo de Predicci√≥n

```
Muestra #1
Real: 2847246203 | Pred: 2650000000
Error: 6.9%
```

**Interpretaci√≥n:**
- El modelo predijo que la pel√≠cula ganar√≠a $2,650,000,000
- La ganancia real fue $2,847,246,203
- El error fue de 6.9%, lo cual es bastante bueno

### M√©tricas de Regresi√≥n

#### R¬≤ Score (Coeficiente de Determinaci√≥n)
- **Rango:** 0 a 1 (puede ser negativo si el modelo es muy malo)
- **Interpretaci√≥n:**
  - 1.0 = Predicci√≥n perfecta
  - 0.8-0.9 = Muy bueno
  - 0.6-0.8 = Bueno
  - 0.4-0.6 = Regular
  - < 0.4 = Malo

**Ejemplo:** R¬≤ = 0.85 significa que el modelo explica el 85% de la varianza en la ganancia.

#### RMSE (Root Mean Squared Error)
- **Interpretaci√≥n:** Error promedio en las mismas unidades que la variable objetivo
- **Ejemplo:** RMSE = 150,000,000 significa que en promedio el modelo se equivoca por $150 millones

#### MAE (Mean Absolute Error)
- **Interpretaci√≥n:** Error absoluto promedio
- **Ejemplo:** MAE = 100,000,000 significa que en promedio el error es de $100 millones

### Gr√°ficos de Predicci√≥n

#### 1. Comparaci√≥n Real vs Predicho
- **L√≠nea azul:** Valores reales
- **L√≠nea verde:** Valores predichos
- **Ideal:** Las dos l√≠neas deben estar muy cerca

#### 2. Distribuci√≥n de Errores
- **Barras:** Porcentaje de error por cada predicci√≥n
- **Ideal:** Barras bajas y uniformes

#### 3. Gr√°fico de Dispersi√≥n
- **Puntos:** Cada predicci√≥n (X = real, Y = predicho)
- **L√≠nea diagonal:** Predicci√≥n perfecta
- **Ideal:** Puntos cerca de la l√≠nea diagonal

## üé® Visualizaciones en el M√≥dulo Resultados

### Pesta√±a "Predicciones"

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üìà √öltimas Predicciones                            ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Muestra #1                                         ‚îÇ
‚îÇ  [Real: 2847246203 | Pred: 2650000000] Error: 6.9% ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Muestra #2                                         ‚îÇ
‚îÇ  [Real: 2187463944 | Pred: 2100000000] Error: 4.0% ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üìä Comparaci√≥n Real vs Predicho                    ‚îÇ
‚îÇ  [Gr√°fico de l√≠neas con valores reales y predichos]‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üìä Distribuci√≥n de Errores                         ‚îÇ
‚îÇ  [Gr√°fico de barras con % de error por muestra]    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üìä Gr√°fico de Dispersi√≥n                           ‚îÇ
‚îÇ  [Scatter plot: Real vs Predicho]                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üìä Estad√≠sticas de Error                           ‚îÇ
‚îÇ  Error Promedio: 125M | Error % Promedio: 5.2%     ‚îÇ
‚îÇ  Error M√≠nimo: 50M    | Error M√°ximo: 300M          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üí° Consejos para Mejorar las Predicciones

### 1. Calidad de los Datos
- **M√°s datos = mejor modelo**: Intenta tener al menos 100-200 pel√≠culas
- **Datos limpios**: Elimina valores nulos y duplicados
- **Datos relevantes**: Aseg√∫rate de que las caracter√≠sticas realmente influyen en la ganancia

### 2. Selecci√≥n de Caracter√≠sticas
**Buenas caracter√≠sticas para predecir ganancia:**
- ‚úÖ Inversi√≥n (presupuesto)
- ‚úÖ G√©nero de la pel√≠cula
- ‚úÖ Pa√≠s de producci√≥n
- ‚úÖ Fecha de estreno (mes, a√±o)
- ‚úÖ Director famoso (si tienes esta info)
- ‚úÖ Actores principales (si tienes esta info)

**Caracter√≠sticas que NO ayudan:**
- ‚ùå Nombre de la pel√≠cula (cada pel√≠cula es √∫nica)
- ‚ùå ID o identificadores √∫nicos

### 3. Elecci√≥n del Modelo

**Random Forest (Scikit-learn):**
- ‚úÖ Bueno para datasets peque√±os/medianos
- ‚úÖ R√°pido de entrenar
- ‚úÖ Maneja bien caracter√≠sticas categ√≥ricas
- ‚úÖ Proporciona feature importance

**Gradient Boosting (Scikit-learn):**
- ‚úÖ Generalmente m√°s preciso que Random Forest
- ‚ö†Ô∏è M√°s lento de entrenar
- ‚úÖ Excelente para competencias

**Red Neuronal (PyTorch):**
- ‚úÖ Mejor para datasets grandes (>1000 muestras)
- ‚úÖ Puede capturar relaciones complejas
- ‚ö†Ô∏è Requiere m√°s datos para entrenar bien
- ‚ö†Ô∏è M√°s lento de entrenar

### 4. Ajuste de Hiperpar√°metros

**Para Scikit-learn:**
- Activa "Optimizaci√≥n de hiperpar√°metros" (Grid Search)
- Esto encontrar√° autom√°ticamente los mejores par√°metros

**Para PyTorch:**
- Aumenta √©pocas si el modelo no converge (50-100)
- Aumenta neuronas si el dataset es complejo (128-256)
- Reduce learning rate si el entrenamiento es inestable (0.001-0.0001)

## üîç Ejemplo Completo: Dataset de Pel√≠culas

### Datos de Entrada

```csv
nombre,pais,genero,inversion,fecha,ganancia
Avatar,USA,Sci-Fi,237000000,2009-12-18,2847246203
Titanic,USA,Drama,200000000,1997-12-19,2187463944
Avengers,USA,Action,220000000,2012-05-04,1518812988
Parasite,Korea,Drama,11400000,2019-05-30,258800000
Joker,USA,Drama,55000000,2019-10-04,1074251311
```

### Configuraci√≥n del Modelo

```
Framework: Scikit-learn
Modelo: Random Forest
Caracter√≠sticas: pais, genero, inversion, fecha
Objetivo: ganancia
Tipo de Tarea: Regresi√≥n
Test Size: 20%
```

### Resultados Esperados

```
M√©tricas:
- R¬≤ Score: 0.82 (Bueno - explica 82% de la varianza)
- RMSE: 180,000,000 (Error promedio de $180M)
- MAE: 120,000,000 (Error absoluto promedio de $120M)

Predicciones:
Muestra #1: Real: 2847M | Pred: 2650M | Error: 6.9% ‚úÖ
Muestra #2: Real: 2187M | Pred: 2100M | Error: 4.0% ‚úÖ
Muestra #3: Real: 1518M | Pred: 1450M | Error: 4.5% ‚úÖ
```

## üö® Problemas Comunes y Soluciones

### Problema 1: R¬≤ Score muy bajo (< 0.4)
**Causas:**
- Datos insuficientes
- Caracter√≠sticas no relevantes
- Modelo muy simple

**Soluciones:**
- Consigue m√°s datos
- Agrega m√°s caracter√≠sticas relevantes
- Prueba un modelo m√°s complejo (Gradient Boosting o PyTorch)

### Problema 2: Errores muy grandes
**Causas:**
- Outliers en los datos (pel√≠culas con ganancias extremas)
- Escala de valores muy diferente

**Soluciones:**
- Limpia outliers en el m√≥dulo "Limpiar Datos"
- El sistema ya escala autom√°ticamente, pero verifica los datos

### Problema 3: Overfitting (Train accuracy alta, Test accuracy baja)
**Causas:**
- Modelo muy complejo para pocos datos
- Demasiadas √©pocas en PyTorch

**Soluciones:**
- Reduce complejidad del modelo
- Reduce √©pocas en PyTorch
- Consigue m√°s datos de entrenamiento

## üìö Recursos Adicionales

### Documentaci√≥n del Proyecto
- `ML_IMPLEMENTATION.md` - Documentaci√≥n t√©cnica completa
- `SISTEMA_PREDICCIONES.md` - C√≥mo funciona el sistema de predicciones
- `MEJORAS_MODULO_ENTRENAR.md` - Funcionalidades del m√≥dulo entrenar

### Conceptos de Machine Learning
- **Regresi√≥n vs Clasificaci√≥n**: Regresi√≥n predice n√∫meros, clasificaci√≥n predice categor√≠as
- **Train/Test Split**: Dividir datos para evaluar el modelo en datos no vistos
- **Overfitting**: Cuando el modelo memoriza en vez de aprender patrones generales
- **Feature Engineering**: Crear nuevas caracter√≠sticas a partir de las existentes

## ‚úÖ Checklist de √âxito

- [ ] Datos cargados con al menos 100 muestras
- [ ] Columna objetivo (ganancia) es num√©rica
- [ ] Caracter√≠sticas seleccionadas son relevantes
- [ ] Tipo de tarea configurado como "Regresi√≥n"
- [ ] Modelo entrenado exitosamente
- [ ] R¬≤ Score > 0.6
- [ ] Predicciones generadas y visualizadas
- [ ] Gr√°ficos muestran buena correlaci√≥n entre real y predicho

## üéØ Conclusi√≥n

Con este sistema puedes:
1. ‚úÖ Predecir la ganancia de pel√≠culas bas√°ndote en caracter√≠sticas
2. ‚úÖ Visualizar las predicciones de forma gr√°fica
3. ‚úÖ Evaluar el rendimiento del modelo con m√∫ltiples m√©tricas
4. ‚úÖ Comparar diferentes modelos (Scikit-learn vs PyTorch)
5. ‚úÖ Exportar y guardar los resultados

**¬°Ahora est√°s listo para predecir ganancias con Machine Learning!** üöÄ

